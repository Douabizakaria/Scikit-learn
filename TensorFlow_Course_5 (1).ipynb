{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517b8417-cf92-466e-917b-816a8eec97db",
      "metadata": {
        "id": "517b8417-cf92-466e-917b-816a8eec97db"
      },
      "outputs": [],
      "source": [
        "# Based on the TensFlow course : https://www.tensorflow.org/tutorials/keras/text_classification\n",
        "# Modified by Mehdi Ammi, Univ. Paris 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36a88510-ae6a-4eb5-9b9c-553cad3eb183",
      "metadata": {
        "id": "36a88510-ae6a-4eb5-9b9c-553cad3eb183"
      },
      "source": [
        "# TensorFlow: Text classification\n",
        "\n",
        "In this notebook, you'll learn how to perform text classification starting from plain text files stored on disk. Specifically, you'll train a binary classifier to analyze sentiment using an IMDB dataset. By the end of the notebook, there's an exercise for you to try, where you'll train a multi-class classifier to predict tags for programming questions on Stack Overflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d32093b-ad15-4418-856f-1e68b6d2d49f",
      "metadata": {
        "id": "4d32093b-ad15-4418-856f-1e68b6d2d49f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "163abe37-39f9-4b17-9ce5-01504a3abc69",
      "metadata": {
        "id": "163abe37-39f9-4b17-9ce5-01504a3abc69"
      },
      "source": [
        "## Sentiment Analysis\n",
        "In this notebook, we'll train a sentiment analysis model to classify movie reviews as either positive or negative, based on the text of the review. This is an example of binary classification, a crucial type of machine learning problem.\n",
        "\n",
        "The dataset used here is the Large Movie Review Dataset, which includes 50,000 movie reviews from the Internet Movie Database. These are split evenly into 25,000 reviews for training and 25,000 reviews for testing.\n",
        "\n",
        "### Download and Explore the IMDB Dataset\n",
        "Let's download and extract the dataset, then examine its directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1302819-8c7e-4fe4-ab59-56627ee666ac",
      "metadata": {
        "id": "c1302819-8c7e-4fe4-ab59-56627ee666ac"
      },
      "outputs": [],
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d12fc7-1834-4a04-81c0-546cd0eca92e",
      "metadata": {
        "id": "38d12fc7-1834-4a04-81c0-546cd0eca92e"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "84125825/84125825 ━━━━━━━━━━━━━━━━━━━━ 5s 0us/step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d3bde3-f92b-42b6-8234-d0d0dc04aebc",
      "metadata": {
        "id": "09d3bde3-f92b-42b6-8234-d0d0dc04aebc"
      },
      "outputs": [],
      "source": [
        "os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d662e42-a98c-4338-9902-e496b356003b",
      "metadata": {
        "id": "0d662e42-a98c-4338-9902-e496b356003b"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "['imdb.vocab', 'README', 'test', 'imdbEr.txt', 'train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd64f81-b4fd-49c9-950a-fb7ae03a5b9f",
      "metadata": {
        "id": "2bd64f81-b4fd-49c9-950a-fb7ae03a5b9f"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d9bfa5-348b-4820-b853-c17d1f3024e6",
      "metadata": {
        "id": "e6d9bfa5-348b-4820-b853-c17d1f3024e6"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "['unsup',\n",
        " 'urls_neg.txt',\n",
        " 'labeledBow.feat',\n",
        " 'unsupBow.feat',\n",
        " 'neg',\n",
        " 'urls_unsup.txt',\n",
        " 'urls_pos.txt',\n",
        " 'pos']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fac2fbe-1e1b-46b1-8164-208f9bd1a3d8",
      "metadata": {
        "id": "5fac2fbe-1e1b-46b1-8164-208f9bd1a3d8"
      },
      "source": [
        "### Sample a Review\n",
        "Let's take a look at one of the movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eab65fe-333b-4f18-be5b-04595a10f706",
      "metadata": {
        "id": "0eab65fe-333b-4f18-be5b-04595a10f706"
      },
      "outputs": [],
      "source": [
        "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6b3bdc-f037-460c-b39f-2df90f0cc579",
      "metadata": {
        "id": "6e6b3bdc-f037-460c-b39f-2df90f0cc579"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497fc44a-27ce-40d7-b918-3d9bad44294b",
      "metadata": {
        "id": "497fc44a-27ce-40d7-b918-3d9bad44294b"
      },
      "source": [
        "### Load the Dataset\n",
        "Next, we'll load the data from disk and prepare it for training. We'll use the text_dataset_from_directory utility, which expects a specific directory structure. Before doing that, let's remove unnecessary folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d4b3ba-2512-43d5-87d9-7fff57559897",
      "metadata": {
        "id": "00d4b3ba-2512-43d5-87d9-7fff57559897"
      },
      "outputs": [],
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd72455-5612-4a74-a22d-869dee3e68bd",
      "metadata": {
        "id": "2cd72455-5612-4a74-a22d-869dee3e68bd"
      },
      "outputs": [],
      "source": [
        "# Define the batch size for the dataset\n",
        "batch_size = 32\n",
        "\n",
        "# Define the seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Load the raw training dataset using the text_dataset_from_directory utility\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',  # Path to the directory containing the training data\n",
        "    batch_size=batch_size,  # Set the batch size\n",
        "    validation_split=0.2,  # Specify the fraction of data to be used for validation (20%)\n",
        "    subset='training',  # Indicate that this subset is for training\n",
        "    seed=seed  # Set the seed for reproducibility of the data split\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d7ec43f-2188-4cc5-ab3a-e8801c759278",
      "metadata": {
        "id": "3d7ec43f-2188-4cc5-ab3a-e8801c759278"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Found 25000 files belonging to 2 classes.\n",
        "Using 20000 files for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e9c4add-a4a1-4131-80c3-b87280c38561",
      "metadata": {
        "id": "9e9c4add-a4a1-4131-80c3-b87280c38561"
      },
      "outputs": [],
      "source": [
        "As you can see above, there are 25,000 examples in the training folder, of which you will use 80% (or 20,000) for training. As you will see in a moment, you can train a model by passing a dataset directly to model.fit. If you're new to tf.data, you can also iterate over the dataset and print out a few examples as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d4fcc61-1870-4176-8a0d-01bb68cbe933",
      "metadata": {
        "id": "4d4fcc61-1870-4176-8a0d-01bb68cbe933"
      },
      "source": [
        "### Explore the Data\n",
        "\n",
        "Let's examine a few examples from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf45d89-c4a0-4e29-a3bb-b5241a0ea59e",
      "metadata": {
        "id": "5cf45d89-c4a0-4e29-a3bb-b5241a0ea59e"
      },
      "outputs": [],
      "source": [
        "# Iterate over one batch of data from the raw training dataset\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    # Loop through the first three examples in the batch\n",
        "    for i in range(3):\n",
        "        # Print the text of the review\n",
        "        print(\"Review\", text_batch.numpy()[i])\n",
        "        # Print the label of the review\n",
        "        print(\"Label\", label_batch.numpy()[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab969abb-6647-4a81-bab8-6eddbed73bfb",
      "metadata": {
        "id": "ab969abb-6647-4a81-bab8-6eddbed73bfb"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Review b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
        "Label 0\n",
        "Review b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
        "Label 0\n",
        "Review b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
        "Label 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c025a3a1-1eed-470d-b587-5190a1199ee6",
      "metadata": {
        "id": "c025a3a1-1eed-470d-b587-5190a1199ee6"
      },
      "source": [
        "Notice the reviews contain raw text (with punctuation and occasional HTML tags like <br/>). You will show how to handle these in the following section.\n",
        "\n",
        "The labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the class_names property on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7e84c8-700a-4365-b8d6-152267d11296",
      "metadata": {
        "id": "5c7e84c8-700a-4365-b8d6-152267d11296"
      },
      "outputs": [],
      "source": [
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a42d234-6bb0-4f5f-ac52-fcf0cea70f09",
      "metadata": {
        "id": "9a42d234-6bb0-4f5f-ac52-fcf0cea70f09"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Label 0 corresponds to neg\n",
        "Label 1 corresponds to pos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "505da54d-90b0-4863-9402-8b825ceebac3",
      "metadata": {
        "id": "505da54d-90b0-4863-9402-8b825ceebac3"
      },
      "source": [
        "### Create Validation and Test Datasets\n",
        "\n",
        "Next, let's create a validation dataset and load the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e108a8-3683-45a8-b11c-ea45a8b0095f",
      "metadata": {
        "id": "56e108a8-3683-45a8-b11c-ea45a8b0095f"
      },
      "outputs": [],
      "source": [
        "# Create a validation dataset using the remaining 20% of the training data\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "# Load the test dataset\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44cd6217",
      "metadata": {
        "id": "44cd6217"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Found 25000 files belonging to 2 classeX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04c87d4-f4c2-4fd5-a01a-59d8d39b7785",
      "metadata": {
        "id": "e04c87d4-f4c2-4fd5-a01a-59d8d39b7785"
      },
      "source": [
        "### Prepare the dataset for training\n",
        "\n",
        "Next, you will standardize, tokenize, and vectorize the data using the helpful tf.keras.layers.TextVectorization layer.\n",
        "\n",
        "Standardization refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words, by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer.\n",
        "\n",
        "As you saw above, the reviews contain various HTML tags like <br />. These tags will not be removed by the default standardizer in the TextVectorization layer (which converts text to lowercase and strips punctuation by default, but doesn't strip HTML). You will write a custom standardization function to remove the HTML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "584d27f7",
      "metadata": {
        "id": "584d27f7"
      },
      "outputs": [],
      "source": [
        "# Custom standardization function to remove HTML tags and punctuation\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f587b06-c343-46c0-a0f8-882e07225660",
      "metadata": {
        "id": "9f587b06-c343-46c0-a0f8-882e07225660"
      },
      "source": [
        "Next, you will create a TextVectorization layer. You will use this layer to standardize, tokenize, and vectorize our data. You set the output_mode to int to create unique integer indices for each token.\n",
        "\n",
        "Note that you're using the default split function, and the custom standardization function you defined above. You'll also define some constants for the model, like an explicit maximum sequence_length, which will cause the layer to pad or truncate sequences to exactly sequence_length values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d23370-dde9-4d05-8de4-a3816fe0ef51",
      "metadata": {
        "id": "f9d23370-dde9-4d05-8de4-a3816fe0ef51"
      },
      "outputs": [],
      "source": [
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "# Create a TextVectorization layer with custom standardization\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd1dea1-7bd1-4afa-948f-862e4a44894e",
      "metadata": {
        "id": "6fd1dea1-7bd1-4afa-948f-862e4a44894e"
      },
      "source": [
        "Next, you will call adapt to fit the state of the preprocessing layer to the dataset. This will cause the model to build an index of strings to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09645fbb-2391-49be-9194-3d9ee341a21b",
      "metadata": {
        "id": "09645fbb-2391-49be-9194-3d9ee341a21b"
      },
      "outputs": [],
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428d5723-2e1d-4608-bc0b-2ba3eb04bc98",
      "metadata": {
        "id": "428d5723-2e1d-4608-bc0b-2ba3eb04bc98"
      },
      "source": [
        "### Vectorize the Data\n",
        "\n",
        "Let's create a function to see the result of using this layer to preprocess some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ce25fb-4ce3-444b-9cca-a6f2bc53eda4",
      "metadata": {
        "id": "68ce25fb-4ce3-444b-9cca-a6f2bc53eda4"
      },
      "outputs": [],
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57b71ba-2ee3-4942-8a9d-affa32b511b2",
      "metadata": {
        "id": "a57b71ba-2ee3-4942-8a9d-affa32b511b2"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Review tf.Tensor(b'\"Emma\" was a product of what might be called by the First Great Jane Austen Cycle of the mid-nineties, and it was recently shown on British television, doubtless because of the interest in the author created by the Second Great Jane Austen Cycle which started with \"Pride and Prejudice\" two years ago. We currently have in the cinemas the Austen biopic \"Becoming Jane\", and ITV have recently produced three TV movies based on Austen novels. These include \"Northanger Abbey\", the only one of the six major novels not to have been filmed previously, so the cycle should now be complete. No doubt, however, there will be more to come in the near future. (There is, after all, her juvenile \"Love and Freindship\" (sic), the short novella \"Lady Susan\", and someone, somewhere, has doubtless supplied endings to her two unfinished fragments \"The Watsons\" and \"Sanditon\". Then there are all those Austen sequels churned out by modern writers\\xc2\\x85\\xc2\\x85\\xc2\\x85).<br /><br />The main character is Emma Woodhouse, a young lady from an aristocratic family in Regency England. (Not, as some reviewers have assumed, Victorian England- Austen died before Queen Victoria was even born). Emma is, financially, considerably better off than most Austen heroines such as Elizabeth Bennett or Fanny Price, and has no need to find herself a wealthy husband. Instead, her main preoccupation seems to be finding husbands for her friends. She persuades her friend Harriet to turn down a proposal of marriage from a young farmer, Robert Martin, believing that Harriet should be setting her sights on the ambitious clergyman Mr Elton. This scheme goes disastrously wrong, however, as Elton has no interest in Harriet, but has fallen in love with Emma herself. The speed with which Emma rejects his proposal makes one wonder just why she was so keen to match her friend with a man she regards (with good reason) as an unsuitable marriage partner for herself. This being a Jane Austen plot, Emma turns out to be less of a committed spinster than she seems, and she too finds herself falling in love, leading to further complications.<br /><br />Emma always insists that she will not marry without affection, and when she does find a partner, the handsome Mr Knightley, we feel that this will indeed be an affectionate marriage. It does not, however, seem likely to be a very passionate one (unlike, say, that of Elizabeth Bennett and Mr Darcy). Knightley, who is sixteen years older than Emma (she is 21, he 37), and related to her by marriage, is more like a father-figure than a lover. Much more of a father-figure, in fact, than her actual father, a querulous and selfish old hypochondriac who seems more like her grandfather. When Emma is rude to her unbearably garrulous and tedious friend Miss Bates, it is Knightley who chides her for her lack of manners. (His surname is probably meant to indicate his gentlemanly nature- nineteenth-century gentlemen liked to think of themselves as the modern equivalent of mediaeval knights with their elaborate codes of chivalry). Both Gwyneth Paltrow and Jeremy Northam play their parts very well, but this is not really one of the great screen romances.<br /><br />Of the other characters, I liked Juliet Stephenson\\'s vulgar Mrs Elton and Toni Collette\\'s Harriet. I know that in the novel Harriet was a na\\xc3\\xafve young teenager, whereas here she is more like the character Collette played in \"Muriel\\'s Wedding\"- a gauche, slightly overweight twentysomething, fretting about her chances of finding a man. Nevertheless, I felt that this characterisation worked well in the context of the film and did not detract from Austen\\'s themes.<br /><br />\"Emma\" is one of Austen\\'s more light-hearted works, without the darker overtones of \"Mansfield Park\" or even \"Pride and Prejudice\", and this is reflected on screen. We see a world of beauty and grace, full of stately homes and elegant costumes and fine manners. Apart from the ruffianly gypsies, who make a very brief appearance, the only \"poor\" people we see are Mrs Bates and her daughter, and, as they live in the sort of picturesque rose-strewn thatched cottage which today would change hands for over \\xc2\\xa3500,000, we can be sure that their poverty is relative, not absolute. In Emma\\'s world, poverty is defined as not having your own stately home. This is, of course, not a comprehensive picture of early nineteenth-century life, but nobody has ever claimed Austen as the Regency equivalent of a kitchen-sink realist. Sophisticated romantic comedy, combined with a keen eye for analysing human character, was more in her line.<br /><br />I would not rate this film quite as highly as the 1994 \"Sense and Sensibility\" or the recent \"Pride and Prejudice\"- it tends to drag a bit in the middle, although it has a strong beginning and strong ending- but it is, in the main, a highly enjoyable Austen adaptation. 7/10', shape=(), dtype=string)\n",
        "Label pos\n",
        "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
        "array([[2528,   13,    4, 2218,    5,   48,  227,   26,  488,   32,    2,\n",
        "          83,   86, 1007, 6768, 6996,    5,    2,    1,    3,    9,   13,\n",
        "         986,  581,   20,  681,  708,    1,   84,    5,    2,  598,    8,\n",
        "           2, 2174, 1033,   32,    2,  333,   86, 1007, 6768, 6996,   60,\n",
        "         606,   16, 3114,    3, 5437,  104,  149,  589,   71, 3780,   25,\n",
        "           8,    2, 4959,    2, 6768, 6887, 1587, 1007,    3,    1,   25,\n",
        "         986, 1118,  297,  243,   91,  443,   20, 6768, 2630,  129, 1429,\n",
        "           1,    1,    2,   61,   28,    5,    2, 1539,  653, 2630,   21,\n",
        "           6,   25,   74,  814, 2353,   37,    2, 6996,  139,  148,   26,\n",
        "         555,   57,  803,  189,   47,   76,   26,   50,    6,  203,    8,\n",
        "           2,  781,  701,   47,    7,  101,   30,   39, 3697,  115,    3,\n",
        "           1,    1,    2,  350,    1,  729, 2744,    3,  282, 1116,   43,\n",
        "           1,    1, 4055,    6,   39,  104,    1,    1,    2,    1,    3,\n",
        "           1,   92,   47,   23,   30,  143, 6768, 2141,    1,   44,   32,\n",
        "         709,    1,    2,  275,  106,    7, 2528,    1,    4,  181,  729,\n",
        "          35,   33,    1,  215,    8,    1, 1777,   21,   14,   46, 1870,\n",
        "          25, 5293, 7152, 1777, 6768, 1071,  153, 1573, 2375,   13,   53,\n",
        "        1461, 2528,    7,    1, 5765,  122,  127,   70,   88, 6768, 8660,\n",
        "         135,   14, 2722, 7422,   41,    1, 1841,    3,   43,   57,  349,\n",
        "           6,  163,  733,    4, 3109,  672,  291,   39,  275,    1,  180,\n",
        "           6,   26, 1578, 2978,   15,   39,  335,   55,    1,   39,  469,\n",
        "        5926,    6,  459,  185,    4,    1,    5, 1357,   35,    4,  181,\n",
        "        6023,  639, 1558, 3206,   12, 5926,  139,   26]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9064cf8f-5489-43c9-a8d8-2c9a5e6b21ec",
      "metadata": {
        "id": "9064cf8f-5489-43c9-a8d8-2c9a5e6b21ec"
      },
      "source": [
        "As you can see above, each token has been replaced by an integer. You can lookup the token (string) that each integer corresponds to by calling .get_vocabulary() on the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cc0def-2ea3-4fb3-9c9e-96bf2eb432e7",
      "metadata": {
        "id": "e1cc0def-2ea3-4fb3-9c9e-96bf2eb432e7"
      },
      "outputs": [],
      "source": [
        "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c64d18b-f3f7-455b-a5c1-8ba44281d87a",
      "metadata": {
        "id": "9c64d18b-f3f7-455b-a5c1-8ba44281d87a"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "1287 --->  silent\n",
        " 313 --->  night\n",
        "Vocabulary size: 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8512ed4-b6fe-44ba-bd21-10834ff41eef",
      "metadata": {
        "id": "e8512ed4-b6fe-44ba-bd21-10834ff41eef"
      },
      "source": [
        "### Apply TextVectorization Layer\n",
        "You are nearly ready to train your model. As a final preprocessing step, you will apply the TextVectorization layer you created earlier to the train, validation, and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00c203f6-d637-4272-85c9-b6d167bd6e31",
      "metadata": {
        "id": "00c203f6-d637-4272-85c9-b6d167bd6e31"
      },
      "outputs": [],
      "source": [
        "# Apply the TextVectorization layer to the train, validation, and test datasets\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d6e108-2543-47e8-8a24-a0a92619e9f4",
      "metadata": {
        "id": "e4d6e108-2543-47e8-8a24-a0a92619e9f4"
      },
      "source": [
        "### Configure the dataset for performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975c1073-7699-4b79-b27b-9d92fc3596bf",
      "metadata": {
        "id": "975c1073-7699-4b79-b27b-9d92fc3596bf"
      },
      "source": [
        "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
        "\n",
        ".cache() keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
        "\n",
        ".prefetch() overlaps data preprocessing and model execution while training.\n",
        "\n",
        "You can learn more about both methods, as well as how to cache data to disk in the data performance guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b44320-ada9-44a0-95f1-7a58285ee8c9",
      "metadata": {
        "id": "e5b44320-ada9-44a0-95f1-7a58285ee8c9"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8599b2a5-c9df-4d8e-b408-c9e1911f9085",
      "metadata": {
        "id": "8599b2a5-c9df-4d8e-b408-c9e1911f9085"
      },
      "source": [
        "### Create the model\n",
        "\n",
        "It's time to create your neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12280068-1b94-4fd6-aa03-4d60c4bed02b",
      "metadata": {
        "id": "12280068-1b94-4fd6-aa03-4d60c4bed02b"
      },
      "outputs": [],
      "source": [
        "# Define the embedding dimension size\n",
        "embedding_dim = 16\n",
        "\n",
        "# Build the model using a Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  # Add an Embedding layer to map input tokens to vectors of size embedding_dim\n",
        "  layers.Embedding(max_features, embedding_dim),\n",
        "\n",
        "  # Add a Dropout layer to reduce overfitting by randomly setting input units to 0 with a frequency of 20% at each step\n",
        "  layers.Dropout(0.2),\n",
        "\n",
        "  # Add a GlobalAveragePooling1D layer to reduce the dimensionality of the input\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "\n",
        "  # Add another Dropout layer to reduce overfitting\n",
        "  layers.Dropout(0.2),\n",
        "\n",
        "  # Add a Dense layer with a single unit and a sigmoid activation function for binary classification\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model summary to see the structure and number of parameters\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d5ac84-5a99-4316-9f5a-80ee5f41646c",
      "metadata": {
        "id": "82d5ac84-5a99-4316-9f5a-80ee5f41646c"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #\n",
        "=================================================================\n",
        " embedding (Embedding)       (None, None, 16)          160000\n",
        "\n",
        " dropout (Dropout)           (None, None, 16)          0\n",
        "\n",
        " global_average_pooling1d (  (None, 16)                0\n",
        " GlobalAveragePooling1D)\n",
        "\n",
        " dropout_1 (Dropout)         (None, 16)                0\n",
        "\n",
        " dense (Dense)               (None, 1)                 17\n",
        "\n",
        "=================================================================\n",
        "Total params: 160017 (625.07 KB)\n",
        "Trainable params: 160017 (625.07 KB)\n",
        "Non-trainable params: 0 (0.00 Byte)\n",
        "_________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25e02a02-2de9-46af-970c-92b13b525dcc",
      "metadata": {
        "id": "25e02a02-2de9-46af-970c-92b13b525dcc"
      },
      "source": [
        "The layers are stacked sequentially to build the classifier:\n",
        "\n",
        "1. The first layer is an Embedding layer. This layer takes the integer-encoded reviews and looks up an embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding). To learn more about embeddings, check out the Word embeddings tutorial.\n",
        "2. Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
        "3. The last layer is densely connected with a single output node.\n",
        "\n",
        "### Loss function and optimizer\n",
        "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), you'll use losses.BinaryCrossentropy loss function.\n",
        "\n",
        "We'll compile the model with a loss function and an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d9ba18-0d13-4f00-8a80-3da8e8116c25",
      "metadata": {
        "id": "46d9ba18-0d13-4f00-8a80-3da8e8116c25"
      },
      "outputs": [],
      "source": [
        "# Compile the model with BinaryCrossentropy loss and Adam optimizer\n",
        "model.compile(loss=losses.BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67ce040-a4e2-461d-9901-1951e37fbf6b",
      "metadata": {
        "id": "e67ce040-a4e2-461d-9901-1951e37fbf6b"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "You will train the model by passing the dataset object to the fit method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51963a87-c698-4184-9a23-c366b6fc3f98",
      "metadata": {
        "id": "51963a87-c698-4184-9a23-c366b6fc3f98"
      },
      "outputs": [],
      "source": [
        "# Set the number of epochs for training\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,  # The training dataset\n",
        "    validation_data=val_ds,  # The validation dataset\n",
        "    epochs=epochs  # Number of epochs to train the model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f756e00a-ad8e-4763-9c22-17e65586aea0",
      "metadata": {
        "id": "f756e00a-ad8e-4763-9c22-17e65586aea0"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "Epoch 1/10\n",
        "625/625 [==============================] - 12s 17ms/step - loss: 0.6660 - binary_accuracy: 0.6908 - val_loss: 0.6178 - val_binary_accuracy: 0.7740\n",
        "Epoch 2/10\n",
        "625/625 [==============================] - 6s 10ms/step - loss: 0.5513 - binary_accuracy: 0.7987 - val_loss: 0.5003 - val_binary_accuracy: 0.8202\n",
        "Epoch 3/10\n",
        "625/625 [==============================] - 5s 8ms/step - loss: 0.4468 - binary_accuracy: 0.8446 - val_loss: 0.4213 - val_binary_accuracy: 0.8464\n",
        "Epoch 4/10\n",
        "625/625 [==============================] - 6s 10ms/step - loss: 0.3800 - binary_accuracy: 0.8655 - val_loss: 0.3746 - val_binary_accuracy: 0.8610\n",
        "Epoch 5/10\n",
        "625/625 [==============================] - 5s 9ms/step - loss: 0.3364 - binary_accuracy: 0.8791 - val_loss: 0.3457 - val_binary_accuracy: 0.8674\n",
        "Epoch 6/10\n",
        "625/625 [==============================] - 7s 11ms/step - loss: 0.3058 - binary_accuracy: 0.8887 - val_loss: 0.3265 - val_binary_accuracy: 0.8716\n",
        "Epoch 7/10\n",
        "625/625 [==============================] - 6s 10ms/step - loss: 0.2832 - binary_accuracy: 0.8954 - val_loss: 0.3130 - val_binary_accuracy: 0.8736\n",
        "Epoch 8/10\n",
        "625/625 [==============================] - 7s 12ms/step - loss: 0.2638 - binary_accuracy: 0.9039 - val_loss: 0.3037 - val_binary_accuracy: 0.8752\n",
        "Epoch 9/10\n",
        "625/625 [==============================] - 6s 10ms/step - loss: 0.2467 - binary_accuracy: 0.9099 - val_loss: 0.2967 - val_binary_accuracy: 0.8758\n",
        "Epoch 10/10\n",
        "625/625 [==============================] - 8s 13ms/step - loss: 0.2324 - binary_accuracy: 0.9168 - val_loss: 0.2921 - val_binary_accuracy: 0.8782"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14349cda-7a6c-467b-b2bb-dab5da0dc16f",
      "metadata": {
        "id": "14349cda-7a6c-467b-b2bb-dab5da0dc16f"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120667fd-8e6f-42f2-a424-d50d87ff0923",
      "metadata": {
        "id": "120667fd-8e6f-42f2-a424-d50d87ff0923"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e31031-d752-4898-ad7e-772e7b102bf5",
      "metadata": {
        "id": "21e31031-d752-4898-ad7e-772e7b102bf5"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "782/782 [==============================] - 4s 5ms/step - loss: 0.3104 - binary_accuracy: 0.8733\n",
        "Loss:  0.31035059690475464\n",
        "Accuracy:  0.8733199834823608"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d586a3-7a09-4a2c-99c0-f8dc9306fa43",
      "metadata": {
        "id": "13d586a3-7a09-4a2c-99c0-f8dc9306fa43"
      },
      "source": [
        "### Plot Accuracy and Loss over time\n",
        "\n",
        "model.fit() returns a History object that contains a dictionary with everything that happened during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffceefb3-97d7-47ee-bacc-1df4958c3c25",
      "metadata": {
        "id": "ffceefb3-97d7-47ee-bacc-1df4958c3c25"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76387f4-b2df-4285-b2b1-7d5fac754bb0",
      "metadata": {
        "id": "b76387f4-b2df-4285-b2b1-7d5fac754bb0"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797505d5-9972-4f96-be2b-679906e2b6f5",
      "metadata": {
        "id": "797505d5-9972-4f96-be2b-679906e2b6f5"
      },
      "source": [
        "We'll create plots for the training and validation accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3277cb52-d0ab-496a-9198-7bd61783a048",
      "metadata": {
        "id": "3277cb52-d0ab-496a-9198-7bd61783a048"
      },
      "outputs": [],
      "source": [
        "# Retrieve history of accuracy and loss\n",
        "history_dict = history.history\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d2b168-42ea-4df7-b931-612e92cafe59",
      "metadata": {
        "id": "82d2b168-42ea-4df7-b931-612e92cafe59"
      },
      "source": [
        "![text_plot1.png](attachment:43063a6b-72cb-46d8-b953-ce0fc8ad623b.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f652027-a0ea-4181-892d-e5cf9f046114",
      "metadata": {
        "id": "1f652027-a0ea-4181-892d-e5cf9f046114"
      },
      "source": [
        "![text_plot2.png](attachment:1cff0cd1-b2d1-4ee5-ba7f-94e417a4d058.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f0bea1a-64bb-4439-9f12-89bfb2ab93a8",
      "metadata": {
        "id": "9f0bea1a-64bb-4439-9f12-89bfb2ab93a8"
      },
      "source": [
        "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
        "\n",
        "Notice the training loss decreases with each epoch and the training accuracy increases with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
        "\n",
        "This isn't the case for the validation loss and accuracy—they seem to peak before the training accuracy. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data.\n",
        "\n",
        "For this particular case, you could prevent overfitting by simply stopping the training when the validation accuracy is no longer increasing. One way to do so is to use the tf.keras.callbacks.EarlyStopping callback."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986a09ca-320e-4762-bab6-d43ecb03d1c4",
      "metadata": {
        "id": "986a09ca-320e-4762-bab6-d43ecb03d1c4"
      },
      "source": [
        "## Export the model\n",
        "In the code above, you applied the TextVectorization layer to the dataset before feeding text to the model. If you want to make your model capable of processing raw strings (for example, to simplify deploying it), you can include the TextVectorization layer inside your model. To do so, you can create a new model using the weights you just trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc23aabd-056f-4cb4-b79b-b0a8cee61452",
      "metadata": {
        "id": "fc23aabd-056f-4cb4-b79b-b0a8cee61452"
      },
      "outputs": [],
      "source": [
        "# Create an export model including the TextVectorization layer\n",
        "export_model = tf.keras.Sequential([\n",
        "  vectorize_layer,\n",
        "  model,\n",
        "  layers.Activation('sigmoid')\n",
        "])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Evaluate the export model on the raw test dataset\n",
        "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286a87bc-b82e-41d6-8be4-a0821199cfa2",
      "metadata": {
        "id": "286a87bc-b82e-41d6-8be4-a0821199cfa2"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "782/782 [==============================] - 8s 10ms/step - loss: 0.5889 - accuracy: 0.5000\n",
        "0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ad7554-1588-42bf-b4a9-3dadb3b7533c",
      "metadata": {
        "id": "e9ad7554-1588-42bf-b4a9-3dadb3b7533c"
      },
      "source": [
        "### Inference on new data\n",
        "To get predictions for new examples, you can simply call model.predict()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f14d835-768f-424a-b206-185f0e3f603c",
      "metadata": {
        "id": "4f14d835-768f-424a-b206-185f0e3f603c"
      },
      "outputs": [],
      "source": [
        "# Predict sentiments of new examples\n",
        "examples = tf.constant([\n",
        "  \"The movie was great!\",\n",
        "  \"The movie was okay.\",\n",
        "  \"The movie was terrible...\"\n",
        "])\n",
        "\n",
        "export_model.predict(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff2b7e7-a5d5-4995-8196-94d7a3e0d8e1",
      "metadata": {
        "id": "cff2b7e7-a5d5-4995-8196-94d7a3e0d8e1"
      },
      "outputs": [],
      "source": [
        ">>\n",
        "1/1 [==============================] - 1s 526ms/step\n",
        "array([[0.6534078 ],\n",
        "       [0.61201787],\n",
        "       [0.59269434]], dtype=float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec173b83-b106-4dd1-aec6-93d8bc9b21e8",
      "metadata": {
        "id": "ec173b83-b106-4dd1-aec6-93d8bc9b21e8"
      },
      "source": [
        "Including the text preprocessing logic inside your model enables you to export a model for production that simplifies deployment, and reduces the potential for train/test skew.\n",
        "\n",
        "There is a performance difference to keep in mind when choosing where to apply your TextVectorization layer. Using it outside of your model enables you to do asynchronous CPU processing and buffering of your data when training on GPU. So, if you're training your model on the GPU, you probably want to go with this option to get the best performance while developing your model, then switch to including the TextVectorization layer inside your model when you're ready to prepare for deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014c93a3-9231-4c1f-8bae-b95b4b3bab7d",
      "metadata": {
        "id": "014c93a3-9231-4c1f-8bae-b95b4b3bab7d"
      },
      "source": [
        "## Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1701e095-8351-4820-afe3-0a8d809bc53c",
      "metadata": {
        "id": "1701e095-8351-4820-afe3-0a8d809bc53c"
      },
      "source": [
        "### Exercise 1: Adjust Batch Size\n",
        "\n",
        " - Adjust the batch size to 64 and observe how it affects the model's training.\n",
        " - Change the batch size to 128 and observe the effects on training and validation accuracy.\n",
        " - Experiment with a batch size of 16 and compare the training time with the previous configurations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Load and preprocess data\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Experiment with different batch sizes\n",
        "batch_sizes = [64, 128, 16]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    print(f\"Training with batch size: {batch_size}\")\n",
        "    history = model.fit(train_images, train_labels, epochs=10, batch_size=batch_size, validation_data=(test_images, test_labels))\n",
        "    print(f\"Training accuracy: {history.history['accuracy'][-1]}, Validation accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "NKr7FmJCpwfO",
        "outputId": "497443e3-2dd6-4194-92a7-6ad0e311ba0e"
      },
      "id": "NKr7FmJCpwfO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with batch size: 64\n",
            "Epoch 1/10\n",
            "\u001b[1m781/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3231 - loss: 1.8234"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ccdeaa28753>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training with batch size: {batch_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training accuracy: {history.history['accuracy'][-1]}, Validation accuracy: {history.history['val_accuracy'][-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    343\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     )\n\u001b[0;32m--> 345\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4adbd24d-fe96-4374-b1c9-b006f55c8e73",
      "metadata": {
        "id": "4adbd24d-fe96-4374-b1c9-b006f55c8e73"
      },
      "source": [
        "### Exercise 2: Increase Embedding Dimension\n",
        "\n",
        " - Increase the embedding dimension to 32.\n",
        " - Increase the embedding dimension to 64 and observe how it affects the model's performance.\n",
        " - Reduce the embedding dimension to 8 and compare the accuracy and loss with the previous configurations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for text classification)\n",
        "num_classes = 10\n",
        "vocab_size = 1000  # Example vocabulary size\n",
        "max_length = 100   # Example max length of input sequences\n",
        "\n",
        "# Define the model with different embedding dimensions\n",
        "embedding_dimensions = [32, 64, 8]\n",
        "\n",
        "for embedding_dim in embedding_dimensions:\n",
        "    print(f\"Training with embedding dimension: {embedding_dim}\")\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Generate dummy data for training\n",
        "    import numpy as np\n",
        "    x_train = np.random.randint(0, vocab_size, size=(1000, max_length))\n",
        "    y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Print final accuracy and loss\n",
        "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "id": "Q-ubR3Wjqhkf"
      },
      "id": "Q-ubR3Wjqhkf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c06d9cb-12ab-4a26-8d84-dde5fe003925",
      "metadata": {
        "id": "2c06d9cb-12ab-4a26-8d84-dde5fe003925"
      },
      "source": [
        "### Exercise 3: Modify Dropout Rate\n",
        "\n",
        " - Modify the dropout rate to 0.3 in the model.\n",
        " - Change the dropout rate to 0.5 and observe the effects on the model's performance.\n",
        " - Set the dropout rate to 0.1 and compare the validation accuracy with the previous configurations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model with different dropout rates\n",
        "dropout_rates = [0.3, 0.5, 0.1]\n",
        "\n",
        "for dropout_rate in dropout_rates:\n",
        "    print(f\"Training with dropout rate: {dropout_rate}\")\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Generate dummy data for training\n",
        "    import numpy as np\n",
        "    x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "    y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Print final accuracy\n",
        "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdJg333mq4dX",
        "outputId": "43ce29f5-eab8-416a-b7c8-b22919355dca"
      },
      "id": "xdJg333mq4dX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with dropout rate: 0.3\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1111 - loss: 2.3615 - val_accuracy: 0.1000 - val_loss: 2.2997\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.1354 - loss: 2.2949 - val_accuracy: 0.0900 - val_loss: 2.3033\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.1176 - loss: 2.2984 - val_accuracy: 0.0750 - val_loss: 2.3025\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1477 - loss: 2.2933 - val_accuracy: 0.0750 - val_loss: 2.3050\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.1287 - loss: 2.2895 - val_accuracy: 0.0750 - val_loss: 2.3050\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1358 - loss: 2.2850 - val_accuracy: 0.1050 - val_loss: 2.3039\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1275 - loss: 2.2911 - val_accuracy: 0.0650 - val_loss: 2.3047\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1382 - loss: 2.2918 - val_accuracy: 0.1100 - val_loss: 2.3031\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1419 - loss: 2.2889 - val_accuracy: 0.0850 - val_loss: 2.3049\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1391 - loss: 2.2838 - val_accuracy: 0.0850 - val_loss: 2.3042\n",
            "Final Training Accuracy: 0.13249999284744263, Final Validation Accuracy: 0.08500000089406967\n",
            "Training with dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.0993 - loss: 2.4201 - val_accuracy: 0.1300 - val_loss: 2.2996\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.0779 - loss: 2.3118 - val_accuracy: 0.1300 - val_loss: 2.2992\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0939 - loss: 2.3059 - val_accuracy: 0.1250 - val_loss: 2.3013\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0871 - loss: 2.3052 - val_accuracy: 0.1250 - val_loss: 2.3002\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.1105 - loss: 2.3056 - val_accuracy: 0.1200 - val_loss: 2.3007\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0994 - loss: 2.3015 - val_accuracy: 0.1250 - val_loss: 2.2977\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1237 - loss: 2.3022 - val_accuracy: 0.1250 - val_loss: 2.3011\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1243 - loss: 2.3004 - val_accuracy: 0.1250 - val_loss: 2.2995\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1012 - loss: 2.3032 - val_accuracy: 0.1250 - val_loss: 2.2988\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1179 - loss: 2.2985 - val_accuracy: 0.1250 - val_loss: 2.2977\n",
            "Final Training Accuracy: 0.125, Final Validation Accuracy: 0.125\n",
            "Training with dropout rate: 0.1\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.1021 - loss: 2.3422 - val_accuracy: 0.0800 - val_loss: 2.3113\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.1158 - loss: 2.3013 - val_accuracy: 0.1200 - val_loss: 2.3069\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1235 - loss: 2.2978 - val_accuracy: 0.0900 - val_loss: 2.3097\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1127 - loss: 2.2993 - val_accuracy: 0.0800 - val_loss: 2.3272\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1372 - loss: 2.2914 - val_accuracy: 0.0900 - val_loss: 2.3088\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1137 - loss: 2.2956 - val_accuracy: 0.0800 - val_loss: 2.3193\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.1524 - loss: 2.2878 - val_accuracy: 0.0800 - val_loss: 2.3246\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.1226 - loss: 2.2869 - val_accuracy: 0.0800 - val_loss: 2.3333\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1310 - loss: 2.2924 - val_accuracy: 0.0800 - val_loss: 2.3143\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.1532 - loss: 2.2741 - val_accuracy: 0.0700 - val_loss: 2.3109\n",
            "Final Training Accuracy: 0.14000000059604645, Final Validation Accuracy: 0.07000000029802322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d65ab42-afc0-442e-b0ad-5e66f49a6bdc",
      "metadata": {
        "id": "9d65ab42-afc0-442e-b0ad-5e66f49a6bdc"
      },
      "source": [
        "### Exercise 4: Add Another Dense Layer\n",
        "\n",
        " - Add another Dense layer with 16 units and 'relu' activation before the final Dense layer.\n",
        " - Change the number of units in the added Dense layer to 32 and observe the effects on model performance.\n",
        " - Replace the 'relu' activation with 'tanh' and compare the training and validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model with an additional Dense layer\n",
        "units_list = [16, 32]\n",
        "activation_functions = ['relu', 'tanh']\n",
        "\n",
        "for units in units_list:\n",
        "    for activation in activation_functions:\n",
        "        print(f\"Training with Dense layer of {units} units and '{activation}' activation\")\n",
        "\n",
        "        model = models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(units, activation=activation),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # Generate dummy data for training\n",
        "        import numpy as np\n",
        "        x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "        y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "        # Print final accuracy\n",
        "        print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQE0X-BLrJNS",
        "outputId": "ed7bab50-3f83-4a6d-997e-390ae9b945e1"
      },
      "id": "IQE0X-BLrJNS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Dense layer of 16 units and 'relu' activation\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.0688 - loss: 2.3316 - val_accuracy: 0.1200 - val_loss: 2.3023\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.1265 - loss: 2.3021 - val_accuracy: 0.1200 - val_loss: 2.3020\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1124 - loss: 2.3015 - val_accuracy: 0.1200 - val_loss: 2.3019\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1421 - loss: 2.3002 - val_accuracy: 0.1200 - val_loss: 2.3019\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1153 - loss: 2.3007 - val_accuracy: 0.1200 - val_loss: 2.3018\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1169 - loss: 2.3015 - val_accuracy: 0.1200 - val_loss: 2.3017\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1335 - loss: 2.2989 - val_accuracy: 0.1200 - val_loss: 2.3017\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1101 - loss: 2.3000 - val_accuracy: 0.1200 - val_loss: 2.3020\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1067 - loss: 2.2994 - val_accuracy: 0.1200 - val_loss: 2.3020\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1134 - loss: 2.3011 - val_accuracy: 0.1200 - val_loss: 2.3019\n",
            "Final Training Accuracy: 0.11625000089406967, Final Validation Accuracy: 0.11999999731779099\n",
            "Training with Dense layer of 16 units and 'tanh' activation\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0909 - loss: 2.3607 - val_accuracy: 0.1250 - val_loss: 2.3149\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0877 - loss: 2.3041 - val_accuracy: 0.1250 - val_loss: 2.3017\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1435 - loss: 2.2873 - val_accuracy: 0.0850 - val_loss: 2.3078\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1490 - loss: 2.2685 - val_accuracy: 0.1150 - val_loss: 2.2993\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2781 - loss: 2.1835 - val_accuracy: 0.0950 - val_loss: 2.2971\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5925 - loss: 1.9894 - val_accuracy: 0.0750 - val_loss: 2.3703\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7255 - loss: 1.7072 - val_accuracy: 0.1150 - val_loss: 2.3937\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8662 - loss: 1.2166 - val_accuracy: 0.1050 - val_loss: 2.4954\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9716 - loss: 0.7055 - val_accuracy: 0.1050 - val_loss: 2.7114\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.3649 - val_accuracy: 0.1050 - val_loss: 2.8965\n",
            "Final Training Accuracy: 1.0, Final Validation Accuracy: 0.10499999672174454\n",
            "Training with Dense layer of 32 units and 'relu' activation\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.1121 - loss: 2.3466 - val_accuracy: 0.0900 - val_loss: 2.3085\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1174 - loss: 2.3023 - val_accuracy: 0.0900 - val_loss: 2.3154\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1088 - loss: 2.2985 - val_accuracy: 0.0900 - val_loss: 2.3074\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1364 - loss: 2.2903 - val_accuracy: 0.0900 - val_loss: 2.3112\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1145 - loss: 2.2893 - val_accuracy: 0.0900 - val_loss: 2.3169\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1120 - loss: 2.2781 - val_accuracy: 0.0900 - val_loss: 2.3335\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1434 - loss: 2.2587 - val_accuracy: 0.0850 - val_loss: 2.3106\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1476 - loss: 2.2263 - val_accuracy: 0.0900 - val_loss: 2.3417\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1327 - loss: 2.1928 - val_accuracy: 0.0800 - val_loss: 2.3446\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1840 - loss: 2.1163 - val_accuracy: 0.0700 - val_loss: 2.3187\n",
            "Final Training Accuracy: 0.19875000417232513, Final Validation Accuracy: 0.07000000029802322\n",
            "Training with Dense layer of 32 units and 'tanh' activation\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.1016 - loss: 2.3692 - val_accuracy: 0.1050 - val_loss: 2.3154\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1042 - loss: 2.3069 - val_accuracy: 0.1050 - val_loss: 2.3280\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1072 - loss: 2.2854 - val_accuracy: 0.1150 - val_loss: 2.3122\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3790 - loss: 2.1920 - val_accuracy: 0.0550 - val_loss: 2.3444\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5971 - loss: 1.9587 - val_accuracy: 0.0600 - val_loss: 2.3754\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8166 - loss: 1.6606 - val_accuracy: 0.0650 - val_loss: 2.4824\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9496 - loss: 1.1349 - val_accuracy: 0.1250 - val_loss: 2.5134\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9933 - loss: 0.5973 - val_accuracy: 0.1300 - val_loss: 2.6647\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2501 - val_accuracy: 0.0950 - val_loss: 2.7534\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1131 - val_accuracy: 0.1000 - val_loss: 2.8921\n",
            "Final Training Accuracy: 1.0, Final Validation Accuracy: 0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f95e8455-e847-4649-8581-cf0371e3eec4",
      "metadata": {
        "id": "f95e8455-e847-4649-8581-cf0371e3eec4"
      },
      "source": [
        "### Exercise 5: Change Optimizer to RMSprop\n",
        "\n",
        " - Change the optimizer from 'adam' to 'RMSprop'.\n",
        " - Experiment with the 'sgd' optimizer and compare the model's performance with 'adam' and 'RMSprop'.\n",
        " - Adjust the learning rate of the 'RMSprop' optimizer to 0.001 and observe the effects on training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model\n",
        "def create_model(optimizer):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Experiment with different optimizers\n",
        "optimizers = {\n",
        "    'adam': 'adam',\n",
        "    'RMSprop': tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    'sgd': 'sgd'\n",
        "}\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"Training with optimizer: {name}\")\n",
        "\n",
        "    model = create_model(optimizer)\n",
        "\n",
        "    # Generate dummy data for training\n",
        "    import numpy as np\n",
        "    x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "    y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Print final accuracy\n",
        "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "id": "mV-YYUkBrbnf"
      },
      "id": "mV-YYUkBrbnf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f719bf3e-2714-468c-aae9-b0743306014a",
      "metadata": {
        "id": "f719bf3e-2714-468c-aae9-b0743306014a"
      },
      "source": [
        "### Exercise 6: Use EarlyStopping Callback\n",
        "\n",
        " - Implement EarlyStopping to prevent overfitting.\n",
        " - Modify the patience parameter to 5 and observe how it affects the training process.\n",
        " - Change the monitor parameter to 'val_accuracy' and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Generate dummy data for training\n",
        "import numpy as np\n",
        "x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "# EarlyStopping with patience=5\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model = create_model()\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "id": "lIEP92xuroIL"
      },
      "id": "lIEP92xuroIL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "752b7de8-0f97-4697-a803-71e65e0c6fa7",
      "metadata": {
        "id": "752b7de8-0f97-4697-a803-71e65e0c6fa7"
      },
      "source": [
        "### Exercise 7: Implement L2 Regularization\n",
        "\n",
        " - Add L2 regularization to the Dense layer.\n",
        " - Change the L2 regularization factor to 0.001 and observe the effects on model performance.\n",
        " - Add L2 regularization to the additional Dense layer from Exercise 5 and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model with L2 regularization\n",
        "def create_model(l2_factor):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=l2(l2_factor)),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Generate dummy data for training\n",
        "import numpy as np\n",
        "x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "# Experiment with L2 regularization factor\n",
        "l2_factor = 0.001\n",
        "model = create_model(l2_factor)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "# Adding L2 regularization to the additional Dense layer\n",
        "def create_model_with_additional_dense(l2_factor):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=l2(l2_factor)),\n",
        "        layers.Dense(16, activation='relu', kernel_regularizer=l2(l2_factor)),  # Additional Dense layer\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model with additional Dense layer\n",
        "model_with_additional_dense = create_model_with_additional_dense(l2_factor)\n",
        "model_with_additional_dense.compile(optimizer='adam',\n",
        "                                    loss='sparse_categorical_crossentropy',\n",
        "                                    metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_additional = model_with_additional_dense.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy (with additional Dense layer): {history_additional.history['accuracy'][-1]}, Final Validation Accuracy: {history_additional.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5oKHWBsrpZr",
        "outputId": "1384150d-3131-4e7a-eecd-8b04d4316966"
      },
      "id": "j5oKHWBsrpZr",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.1177 - loss: 2.5215 - val_accuracy: 0.1500 - val_loss: 2.3763\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.1342 - loss: 2.3783 - val_accuracy: 0.1500 - val_loss: 2.3780\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1398 - loss: 2.3217 - val_accuracy: 0.1100 - val_loss: 2.3644\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2428 - loss: 2.2371 - val_accuracy: 0.1050 - val_loss: 2.3913\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.2838 - loss: 2.1583 - val_accuracy: 0.1050 - val_loss: 2.4286\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3239 - loss: 2.0530 - val_accuracy: 0.1400 - val_loss: 2.4321\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5435 - loss: 1.8931 - val_accuracy: 0.0950 - val_loss: 2.4047\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5842 - loss: 1.7882 - val_accuracy: 0.0750 - val_loss: 2.5871\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7071 - loss: 1.5873 - val_accuracy: 0.0800 - val_loss: 2.5021\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7850 - loss: 1.3887 - val_accuracy: 0.1050 - val_loss: 2.5058\n",
            "Final Training Accuracy: 0.8475000262260437, Final Validation Accuracy: 0.10499999672174454\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.1172 - loss: 2.4826 - val_accuracy: 0.0750 - val_loss: 2.4007\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0929 - loss: 2.3917 - val_accuracy: 0.0800 - val_loss: 2.4018\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.1358 - loss: 2.3654 - val_accuracy: 0.1500 - val_loss: 2.3626\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.1143 - loss: 2.3454 - val_accuracy: 0.1050 - val_loss: 2.3652\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1409 - loss: 2.3166 - val_accuracy: 0.1050 - val_loss: 2.3649\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1815 - loss: 2.2601 - val_accuracy: 0.1550 - val_loss: 2.3713\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2475 - loss: 2.1739 - val_accuracy: 0.0900 - val_loss: 2.3912\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3475 - loss: 2.0757 - val_accuracy: 0.0900 - val_loss: 2.4764\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3251 - loss: 1.9939 - val_accuracy: 0.0800 - val_loss: 2.4495\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4242 - loss: 1.8165 - val_accuracy: 0.0700 - val_loss: 2.5066\n",
            "Final Training Accuracy (with additional Dense layer): 0.45124998688697815, Final Validation Accuracy: 0.07000000029802322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8b788cd-3324-41cb-a4e2-bf386d692839",
      "metadata": {
        "id": "c8b788cd-3324-41cb-a4e2-bf386d692839"
      },
      "source": [
        "### Exercise 8: Implement Text Augmentation\n",
        "\n",
        " - Implement text augmentation to the dataset to improve model generalization.\n",
        " - Experiment with different text augmentation techniques such as synonym replacement or random insertion and observe the effects on model performance.\n",
        " - Compare the results of training the model with and without text augmentation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import nlpaug.augmenter.word as naw\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk # import nltk\n",
        "\n",
        "# Download the necessary NLTK resource\n",
        "nltk.download('averaged_perceptron_tagger') # Download the missing resource\n",
        "\n",
        "# Sample data (e.g., for a text classification task)\n",
        "texts = [\"I love programming.\", \"Python is great for data science.\", \"Deep learning is fascinating.\"]\n",
        "labels = [1, 1, 1]  # Example labels\n",
        "\n",
        "# Text augmentation functions\n",
        "def augment_texts(texts, technique='synonym'):\n",
        "    aug = None\n",
        "    if technique == 'synonym':\n",
        "        aug = naw.SynonymAug(aug_p=0.1)  # 10% of words will be replaced with synonyms\n",
        "    elif technique == 'insertion':\n",
        "        aug = naw.RandomWordAug(action=\"insert\", aug_p=0.1)  # 10% of words will be inserted\n",
        "\n",
        "    augmented_texts = [aug.augment(text) for text in texts]\n",
        "    return augmented_texts\n",
        "\n",
        "# Prepare data\n",
        "def prepare_data(texts, labels, augment=False, technique=None):\n",
        "    if augment:\n",
        "        texts = augment_texts(texts, technique)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokenizer = Tokenizer(num_words=1000) # Assuming a vocabulary size of 1000\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Pad sequences to have the same length\n",
        "    x_train = pad_sequences(sequences, maxlen=10) # Assuming a maximum sequence length of 10\n",
        "    y_train = np.array(labels)\n",
        "    return x_train, y_train\n",
        "\n",
        "# Create a simple model\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=1000, output_dim=64, input_length=10),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare data without augmentation\n",
        "x_train, y_train = prepare_data(texts, labels)\n",
        "\n",
        "# Train the model without augmentation\n",
        "model = create_model()\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=2)\n",
        "\n",
        "# Prepare data with synonym augmentation\n",
        "x_train_augmented, y_train_augmented = prepare_data(texts, labels, augment=True, technique='synonym')\n",
        "\n",
        "# Train the model with synonym augmentation\n",
        "model_augmented = create_model()\n",
        "model_augmented.fit(x_train_augmented, y_train_augmented, epochs=10, batch_size=2)\n",
        "\n",
        "# Prepare data with random insertion augmentation\n",
        "x_train_augmented_insertion, y_train_augmented_insertion = prepare_data(texts, labels, augment=True, technique='insertion')\n",
        "\n",
        "# Train the model with random insertion augmentation\n",
        "model_augmented_insertion = create_model()\n",
        "model_augmented_insertion.fit(x_train_augmented_insertion, y_train_augmented_insertion, epochs=10, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ujHcgd-kstsQ",
        "outputId": "8dd6bee9-2977-4d91-fcd8-31ea2b6a9e04"
      },
      "id": "ujHcgd-kstsQ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.6882\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.6765 \n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6687 \n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.6579 \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.6500 \n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6379 \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.6294 \n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6208 \n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6090 \n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.5978 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nlpaug/model/word_dict/wordnet.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(cls, tokens)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load, lang)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mload_from_json\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Automatically find path to the tagger if location is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"taggers/averaged_perceptron_tagger_{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTAGGER_JSONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6488d6d80bef>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Prepare data with synonym augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mx_train_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtechnique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'synonym'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Train the model with synonym augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6488d6d80bef>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(texts, labels, augment, technique)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtechnique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtechnique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6488d6d80bef>\u001b[0m in \u001b[0;36maugment_texts\u001b[0;34m(texts, technique)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomWordAug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"insert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 10% of words will be inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0maugmented_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maugmented_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6488d6d80bef>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomWordAug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"insert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 10% of words will be inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0maugmented_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maugmented_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nlpaug/base_augmenter.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, data, n, num_thread)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# Single Thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum_thread\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0maugmented_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Multi Thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nlpaug/base_augmenter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# Single Thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum_thread\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0maugmented_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Multi Thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nlpaug/augmenter/word/synonym.py\u001b[0m in \u001b[0;36msubstitute\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0moriginal_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_original_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0maug_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_aug_idxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nlpaug/model/word_dict/wordnet.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(cls, tokens)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load, lang)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tagdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mload_from_json\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Automatically find path to the tagger if location is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"taggers/averaged_perceptron_tagger_{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTAGGER_JSONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b605a5-eaf0-4c45-a44c-c7844cc48b87",
      "metadata": {
        "id": "d5b605a5-eaf0-4c45-a44c-c7844cc48b87"
      },
      "source": [
        "### Exercise 9: Implement Batch Normalization\n",
        "\n",
        " - Task: Add batch normalization layers to the model.\n",
        " - Remove one of the Batch Normalization layers and observe how it affects the training and validation accuracy.\n",
        " - Experiment with placing Batch Normalization layers before the Dropout layers and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for a classification task)\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)  # Example input shape for images\n",
        "\n",
        "# Define the model with Batch Normalization\n",
        "def create_model_with_bn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Generate dummy data for training\n",
        "x_train = np.random.rand(1000, 32, 32, 3)  # Example training data\n",
        "y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "# Train the model with Batch Normalization\n",
        "model_with_bn = create_model_with_bn()\n",
        "model_with_bn.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_with_bn = model_with_bn.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy (with Batch Normalization): {history_with_bn.history['accuracy'][-1]}, Final Validation Accuracy: {history_with_bn.history['val_accuracy'][-1]}\")\n",
        "\n",
        "# Remove one Batch Normalization layer and retrain\n",
        "def create_model_without_one_bn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        # Removed one Batch Normalization layer\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model without one Batch Normalization layer\n",
        "model_without_one_bn = create_model_without_one_bn()\n",
        "model_without_one_bn.compile(optimizer='adam',\n",
        "                              loss='sparse_categorical_crossentropy',\n",
        "                              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_without_one_bn = model_without_one_bn.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy (without one Batch Normalization): {history_without_one_bn.history['accuracy'][-1]}, Final Validation Accuracy: {history_without_one_bn.history['val_accuracy'][-1]}\")\n",
        "\n",
        "# Experiment with placing Batch Normalization before Dropout\n",
        "def create_model_with_bn_before_dropout():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),  # Dropout after Batch Normalization\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model with Batch Normalization before Dropout\n",
        "model_bn_before_dropout = create_model_with_bn_before_dropout()\n",
        "model_bn_before_dropout.compile(optimizer='adam',\n",
        "                                 loss='sparse_categorical_crossentropy',\n",
        "                                 metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_bn_before_dropout = model_bn_before_dropout.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Training Accuracy (BN before Dropout): {history_bn_before_dropout.history['accuracy'][-1]}, Final Validation Accuracy: {history_bn_before_dropout.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLLPrML8t08M",
        "outputId": "9be6a66a-de99-4dce-fc87-af5a0e0d6b84"
      },
      "id": "aLLPrML8t08M",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.1078 - loss: 3.4268 - val_accuracy: 0.0750 - val_loss: 2.3119\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.2493 - loss: 2.4318 - val_accuracy: 0.0750 - val_loss: 2.4231\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.3875 - loss: 1.8389 - val_accuracy: 0.0750 - val_loss: 2.5897\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5533 - loss: 1.2951 - val_accuracy: 0.0750 - val_loss: 2.6928\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6576 - loss: 0.9812 - val_accuracy: 0.0750 - val_loss: 2.8339\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.7801 - loss: 0.7459 - val_accuracy: 0.0750 - val_loss: 2.8489\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8423 - loss: 0.6253 - val_accuracy: 0.0800 - val_loss: 2.9404\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8922 - loss: 0.4785 - val_accuracy: 0.0750 - val_loss: 3.0860\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8997 - loss: 0.4430 - val_accuracy: 0.0850 - val_loss: 3.0988\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9368 - loss: 0.3242 - val_accuracy: 0.0900 - val_loss: 3.2709\n",
            "Final Training Accuracy (with Batch Normalization): 0.918749988079071, Final Validation Accuracy: 0.09000000357627869\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0832 - loss: 2.5127 - val_accuracy: 0.1000 - val_loss: 2.3020\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.0987 - loss: 2.3080 - val_accuracy: 0.1400 - val_loss: 2.3022\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0999 - loss: 2.2941 - val_accuracy: 0.1400 - val_loss: 2.3007\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.1296 - loss: 2.2796 - val_accuracy: 0.1400 - val_loss: 2.3008\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.1689 - loss: 2.2760 - val_accuracy: 0.1250 - val_loss: 2.2996\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.1558 - loss: 2.2487 - val_accuracy: 0.1400 - val_loss: 2.3015\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.1818 - loss: 2.2168 - val_accuracy: 0.1150 - val_loss: 2.3028\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.2497 - loss: 2.1490 - val_accuracy: 0.1400 - val_loss: 2.2986\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.2855 - loss: 2.0355 - val_accuracy: 0.1150 - val_loss: 2.3071\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3515 - loss: 1.8897 - val_accuracy: 0.1200 - val_loss: 2.3051\n",
            "Final Training Accuracy (without one Batch Normalization): 0.35374999046325684, Final Validation Accuracy: 0.11999999731779099\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.0925 - loss: 3.3903 - val_accuracy: 0.1200 - val_loss: 2.3519\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2175 - loss: 2.4439 - val_accuracy: 0.1400 - val_loss: 2.6630\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.3361 - loss: 1.9515 - val_accuracy: 0.1350 - val_loss: 2.8336\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4660 - loss: 1.5346 - val_accuracy: 0.1350 - val_loss: 2.9948\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6247 - loss: 1.1835 - val_accuracy: 0.1350 - val_loss: 3.1341\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7110 - loss: 0.9637 - val_accuracy: 0.1350 - val_loss: 3.3177\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8561 - loss: 0.6849 - val_accuracy: 0.1350 - val_loss: 3.4935\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9283 - loss: 0.4984 - val_accuracy: 0.1300 - val_loss: 3.6123\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9609 - loss: 0.3752 - val_accuracy: 0.1350 - val_loss: 3.6426\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9782 - loss: 0.2960 - val_accuracy: 0.1300 - val_loss: 3.5638\n",
            "Final Training Accuracy (BN before Dropout): 0.9712499976158142, Final Validation Accuracy: 0.12999999523162842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40390ed8-b4fc-4863-a710-c7f3c990dc97",
      "metadata": {
        "id": "40390ed8-b4fc-4863-a710-c7f3c990dc97"
      },
      "source": [
        "### Exercise 10 : Implement Bidirectional LSTM\n",
        "\n",
        "- Replace the GlobalAveragePooling1D layer with a Bidirectional LSTM layer.\n",
        "- Experiment with different numbers of LSTM units (e.g., 32, 128) and observe the effects on the model's performance.\n",
        "- Add another Bidirectional LSTM layer and compare the training and validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdfdd748-0139-4869-a8bb-779450a5da56",
      "metadata": {
        "id": "fdfdd748-0139-4869-a8bb-779450a5da56"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Sample data (e.g., for text classification)\n",
        "num_classes = 10\n",
        "max_features = 10000  # Example vocabulary size\n",
        "sequence_length = 250  # Example max length of input sequences\n",
        "\n",
        "# Generate dummy data for training\n",
        "x_train = np.random.randint(0, max_features, size=(1000, sequence_length))  # Example training data\n",
        "y_train = np.random.randint(0, num_classes, size=(1000,))\n",
        "\n",
        "# Define the model with Bidirectional LSTM\n",
        "def create_model_with_bi_lstm(units):\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=max_features, output_dim=64, input_length=sequence_length),\n",
        "        layers.Bidirectional(layers.LSTM(units, return_sequences=True)),  # First Bidirectional LSTM\n",
        "        layers.Bidirectional(layers.LSTM(units)),  # Second Bidirectional LSTM\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Experiment with different numbers of LSTM units\n",
        "lstm_units_list = [32, 128]\n",
        "\n",
        "for lstm_units in lstm_units_list:\n",
        "    print(f\"Training with {lstm_units} LSTM units\")\n",
        "\n",
        "    model = create_model_with_bi_lstm(lstm_units)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Print final accuracy\n",
        "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "froPrykWwFNA",
        "outputId": "bdb5862a-6f87-4f51-9b24-e9415314e00b"
      },
      "id": "froPrykWwFNA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 32 LSTM units\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 341ms/step - accuracy: 0.1016 - loss: 2.3020 - val_accuracy: 0.0650 - val_loss: 2.3165\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 307ms/step - accuracy: 0.1199 - loss: 2.2793 - val_accuracy: 0.0650 - val_loss: 2.3609\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 347ms/step - accuracy: 0.2379 - loss: 2.0333 - val_accuracy: 0.0700 - val_loss: 2.6973\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - accuracy: 0.5507 - loss: 1.2820 - val_accuracy: 0.0800 - val_loss: 3.2632\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9004 - loss: 0.5291 - val_accuracy: 0.0950 - val_loss: 3.9931\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9917 - loss: 0.1630 - val_accuracy: 0.0950 - val_loss: 4.8978\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 345ms/step - accuracy: 0.9989 - loss: 0.0308 - val_accuracy: 0.1000 - val_loss: 5.5235\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.0800 - val_loss: 5.5661\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.0950 - val_loss: 5.5640\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.1000 - val_loss: 5.8232\n",
            "Final Training Accuracy: 1.0, Final Validation Accuracy: 0.10000000149011612\n",
            "Training with 128 LSTM units\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.1224 - loss: 2.3014 - val_accuracy: 0.0650 - val_loss: 2.3145\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.1445 - loss: 2.2772 - val_accuracy: 0.0750 - val_loss: 2.3283\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3644 - loss: 1.8221 - val_accuracy: 0.0950 - val_loss: 2.9203\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5851 - loss: 1.1369 - val_accuracy: 0.1000 - val_loss: 3.5941\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8352 - loss: 0.5046 - val_accuracy: 0.0900 - val_loss: 4.5420\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.9510 - loss: 0.1576 - val_accuracy: 0.0950 - val_loss: 4.7832\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.9942 - loss: 0.0612 - val_accuracy: 0.1000 - val_loss: 5.3407\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9997 - loss: 0.0168 - val_accuracy: 0.0850 - val_loss: 5.2515\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.0900 - val_loss: 5.7272\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.0950 - val_loss: 5.9881\n",
            "Final Training Accuracy: 1.0, Final Validation Accuracy: 0.0949999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_with_two_bi_lstm(units):\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=max_features, output_dim=64, input_length=sequence_length),\n",
        "        layers.Bidirectional(layers.LSTM(units, return_sequences=True)),  # First Bidirectional LSTM\n",
        "        layers.Bidirectional(layers.LSTM(units, return_sequences=True)),  # Second Bidirectional LSTM\n",
        "        layers.Bidirectional(layers.LSTM(units)),  # Third Bidirectional LSTM\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Experiment with two Bidirectional LSTM layers\n",
        "for lstm_units in lstm_units_list:\n",
        "    print(f\"Training with {lstm_units} LSTM units and two Bidirectional LSTM layers\")\n",
        "\n",
        "    model = create_model_with_two_bi_lstm(lstm_units)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Print final accuracy\n",
        "    print(f\"Final Training Accuracy: {history.history['accuracy'][-1]}, Final Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ0k_CnPwGmE",
        "outputId": "d3063ab6-0905-41ba-9cf7-0a69514f29ff"
      },
      "id": "OQ0k_CnPwGmE",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 32 LSTM units and two Bidirectional LSTM layers\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 541ms/step - accuracy: 0.0915 - loss: 2.3016 - val_accuracy: 0.1100 - val_loss: 2.3174\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 523ms/step - accuracy: 0.1742 - loss: 2.2755 - val_accuracy: 0.0650 - val_loss: 2.4956\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 470ms/step - accuracy: 0.3166 - loss: 1.8011 - val_accuracy: 0.1000 - val_loss: 2.9862\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 497ms/step - accuracy: 0.5582 - loss: 1.1864 - val_accuracy: 0.1050 - val_loss: 3.3784\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 497ms/step - accuracy: 0.8612 - loss: 0.6167 - val_accuracy: 0.0650 - val_loss: 4.1227\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 444ms/step - accuracy: 0.9655 - loss: 0.2143 - val_accuracy: 0.1000 - val_loss: 4.4965\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 496ms/step - accuracy: 0.9948 - loss: 0.0820 - val_accuracy: 0.1050 - val_loss: 5.1253\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 500ms/step - accuracy: 0.9971 - loss: 0.0491 - val_accuracy: 0.1050 - val_loss: 5.5953\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 469ms/step - accuracy: 0.9997 - loss: 0.0191 - val_accuracy: 0.1100 - val_loss: 5.7249\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 498ms/step - accuracy: 0.9999 - loss: 0.0113 - val_accuracy: 0.1150 - val_loss: 5.9323\n",
            "Final Training Accuracy: 0.9987499713897705, Final Validation Accuracy: 0.11500000208616257\n",
            "Training with 128 LSTM units and two Bidirectional LSTM layers\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.0843 - loss: 2.3031 - val_accuracy: 0.0650 - val_loss: 2.3154\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.1517 - loss: 2.2593 - val_accuracy: 0.0750 - val_loss: 2.5341\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.4238 - loss: 1.4597 - val_accuracy: 0.1250 - val_loss: 3.3582\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.7756 - loss: 0.6149 - val_accuracy: 0.0800 - val_loss: 4.5251\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.9326 - loss: 0.2301 - val_accuracy: 0.1050 - val_loss: 4.5176\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.9904 - loss: 0.0599 - val_accuracy: 0.0750 - val_loss: 5.5641\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.9981 - loss: 0.0191 - val_accuracy: 0.0900 - val_loss: 5.6481\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.9972 - loss: 0.0141 - val_accuracy: 0.0950 - val_loss: 5.9122\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0900 - val_loss: 6.2025\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0950 - val_loss: 6.3390\n",
            "Final Training Accuracy: 1.0, Final Validation Accuracy: 0.0949999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06307f73-b589-4305-81dd-6610d85b2e55",
      "metadata": {
        "id": "06307f73-b589-4305-81dd-6610d85b2e55"
      },
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}